%====================================================================
\subsection{Sequential Monte-Carlo (SMC)}
\frame{\frametitle{Outline} \tableofcontents[currentsubsection]}
%====================================================================
\frame{ \frametitle{Sequential Monte-Carlo}

  \paragraph{Example: Hidden Markov models} 
  \begin{itemize}
   \item $\Zbf = (Z_t)_{t \leq t}$ hidden Markov chain
   \item $\Ybf =$ observed sequence
   \item $\thetabf = (\Pi, \gamma):$  transition matrix and emission probabilities
  \end{itemize}

  \pause \bigskip \bigskip 
  \paragraph{Inference.} Need to sample from 
  \begin{itemize}
   \item $p(\thetabf \gv \Ybf)$ (parameter inference)
   \item $p(\Zbf \gv \Ybf)$ (classification)
  \end{itemize}

  \pause \bigskip \bigskip  
  \paragraph{Sequential Monte Carlo.} 
  \begin{itemize}
   \item Monte Carlo (stochastic) counterpart of the forward-backward recurrence
   \item Sequentially sample from $p(Z_t \gv \Ybf_1^t, \Zbf_1^{t-1})$.
  \end{itemize}
}

%====================================================================
\subsection{Approximate Bayesian computation (ABC)}
\frame{\frametitle{Outline} \tableofcontents[currentsubsection]}
%====================================================================
\frame{ \frametitle{When the likelihood is intractable}

  \paragraph{Ex.: Population genetics.} Complex demographic model for which
  \begin{itemize}
   \item we do not know how to compute the likelihood:
   $$
   \ell(\Ybf \gv \thetabf) \text{ intractable}
   $$
   \item but we know how to sample from it 
   $$
   \Ybf^b \sim \ell(\Ybf \gv \thetabf).
   $$
   \end{itemize}
   \ra Importance sampling, Metropolis-Hastings, ... can not be implemented.
   
   \pause \bigskip \bigskip
   \paragraph{Principle.} Get a sample $\{\theta^b\}$ such that
   $$
   \Ybf^b \sim p(\Ybf \gv \thetabf^b) \text{ is 'similar' to } \Ybf_\obs
   $$
}

%====================================================================
\frame{ \frametitle{Approximate Bayesian computation (ABC)}

  \paragraph{Ingredients.} 
  \begin{itemize}
   \item A set a {\sl summary statstics} $\sbf(\Ybf)$
   \item A 'distance' $d(\sbf, \sbf')$
   \item A threshold $\varepsilon$
  \end{itemize}

  \pause \bigskip
  \paragraph{Algorithm.} 
  \begin{itemize}
   \item Compute $\sbf_\obs = \sbf(\Ybf_\obs)$
   \item Until we get $B$ realizations
   \begin{enumerate}
    \item sample $\thetabf' \sim \pi(\thetabf)$ (from the prior)
    \item sample $\Ybf' \sim \ell(\Ybf \gv \thetabf')$ (from the model)
    \item compute $\sbf' = \sbf(\Ybf')$
    \item if $d(\sbf' - \sbf_\obs) < \varepsilon$, keep $\thetabf'$ in the sample
   \end{enumerate}
  \end{itemize}
  
  \pause \bigskip
  \paragraph{Rational.} Do not sample from $p(\thetabf \gv \Ybf)$ but from
  $$
  p(\thetabf \gv d(\sbf(\Ybf) - \sbf(\Ybf_\obs)) < \varepsilon).
  $$

}
